import os
from openai import OpenAI
from dotenv import load_dotenv
from typing import List, Dict

# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆagentç›®å½•ï¼‰
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ENV_FILE = os.path.join(BASE_DIR, '.env')

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡ï¼ˆæŒ‡å®šç»å¯¹è·¯å¾„ï¼‰
load_dotenv(ENV_FILE)

class HelloAgentsLLM:
    """
    ä¸ºæœ¬ä¹¦ "Hello Agents" å®šåˆ¶çš„LLMå®¢æˆ·ç«¯ã€‚
    å®ƒç”¨äºè°ƒç”¨ä»»ä½•å…¼å®¹OpenAIæ¥å£çš„æœåŠ¡ï¼Œå¹¶é»˜è®¤ä½¿ç”¨æµå¼å“åº”ã€‚
    """
    def __init__(self, model: str = None, apiKey: str = None, baseUrl: str = None, timeout: int = None):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯ã€‚ä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå¦‚æœæœªæä¾›ï¼Œåˆ™ä»ç¯å¢ƒå˜é‡åŠ è½½ã€‚
        """
        def get_env_value(key, default=None):
            """è·å–ç¯å¢ƒå˜é‡å€¼ï¼Œè‡ªåŠ¨å»é™¤å¼•å·"""
            value = os.getenv(key, default)
            if value and isinstance(value, str):
                # å»é™¤é¦–å°¾çš„å¼•å·ï¼ˆå•å¼•å·æˆ–åŒå¼•å·ï¼‰
                value = value.strip().strip('"').strip("'")
            return value
        
        self.model = model or get_env_value("LLM_MODEL_ID")
        apiKey = apiKey or get_env_value("LLM_API_KEY")
        baseUrl = baseUrl or get_env_value("LLM_BASE_URL")
        timeout = timeout or int(get_env_value("LLM_TIMEOUT", "60") or "60")
        
        if not all([self.model, apiKey, baseUrl]):
            missing = []
            if not self.model:
                missing.append("LLM_MODEL_ID")
            if not apiKey:
                missing.append("LLM_API_KEY")
            if not baseUrl:
                missing.append("LLM_BASE_URL")
            raise ValueError(f"æ¨¡å‹IDã€APIå¯†é’¥å’ŒæœåŠ¡åœ°å€å¿…é¡»è¢«æä¾›æˆ–åœ¨.envæ–‡ä»¶ä¸­å®šä¹‰ã€‚ç¼ºå°‘: {', '.join(missing)}")
        
        self.client = OpenAI(api_key=apiKey, base_url=baseUrl, timeout=timeout)

    def think(self, messages: List[Dict[str, str]], temperature: float = 0) -> str:
        """
        è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ€è€ƒï¼Œå¹¶è¿”å›å…¶å“åº”ã€‚
        """
        import logging
        logger = logging.getLogger(__name__)
        
        logger.info(f"ğŸ§  è°ƒç”¨ {self.model} æ¨¡å‹...")
        logger.info(f"   å‚æ•°: temperature={temperature}")
        logger.info(f"   æ¶ˆæ¯æ•°: {len(messages)}")
        
        try:
            start_time = __import__('datetime').datetime.now()
            logger.info(f"   å‘èµ· API è¯·æ±‚...")
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                stream=True,
            )
            
            logger.info("   âœ… API è¿æ¥æˆåŠŸï¼Œå¼€å§‹æ¥æ”¶æµå¼å“åº”...")
            collected_content = []
            chunk_count = 0
            
            for chunk in response:
                content = chunk.choices[0].delta.content or ""
                if content:
                    chunk_count += 1
                    print(content, end="", flush=True)
                    collected_content.append(content)
            
            elapsed = (__import__('datetime').datetime.now() - start_time).total_seconds()
            full_response = "".join(collected_content)
            
            print()  # åœ¨æµå¼è¾“å‡ºç»“æŸåæ¢è¡Œ
            logger.info(f"   âœ… å“åº”æ¥æ”¶å®Œæˆ")
            logger.info(f"   æ¥æ”¶å—æ•°: {chunk_count}")
            logger.info(f"   å“åº”é•¿åº¦: {len(full_response)} å­—ç¬¦")
            logger.info(f"   è€—æ—¶: {elapsed:.2f} ç§’")
            logger.info(f"   é€Ÿåº¦: {len(full_response)/elapsed:.1f} å­—ç¬¦/ç§’")
            
            return full_response
        except Exception as e:
            elapsed = (__import__('datetime').datetime.now() - start_time).total_seconds() if 'start_time' in locals() else 0
            logger.error(f"   âŒ è°ƒç”¨LLM APIå¤±è´¥: {e}")
            logger.error(f"   å¤±è´¥æ—¶é—´: {elapsed:.2f} ç§’å")
            logger.error(f"   æ¨¡å‹: {self.model}")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            import traceback
            logger.error(f"   è¯¦ç»†å †æ ˆ:\n{traceback.format_exc()}")
            return None

    def think_stream(self, messages: List[Dict[str, str]], temperature: float = 0):
        """
        æµå¼è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ï¼Œè¿”å›ç”Ÿæˆå™¨ã€‚
        """
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                stream=True,
            )
            
            for chunk in response:
                content = chunk.choices[0].delta.content or ""
                if content:
                    yield content
        except Exception as e:
            print(f"âŒ è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            yield None

# --- å®¢æˆ·ç«¯ä½¿ç”¨ç¤ºä¾‹ ---
if __name__ == '__main__':
    try:
        llmClient = HelloAgentsLLM()
        
        exampleMessages = [
            {"role": "system", "content": "You are a helpful assistant that writes Python code."},
            {"role": "user", "content": "å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•"}
        ]
        
        print("--- è°ƒç”¨LLM ---")
        responseText = llmClient.think(exampleMessages)
        if responseText:
            print("\n\n--- å®Œæ•´æ¨¡å‹å“åº” ---")
            print(responseText)
    except ValueError as e:
        print(e)

