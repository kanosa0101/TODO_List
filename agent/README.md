# AI Agent æœåŠ¡

åŸºäº Flask çš„ LLM å®¢æˆ·ç«¯æœåŠ¡ï¼Œæ”¯æŒ OpenAI å…¼å®¹çš„ APIã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ¤– æ”¯æŒ OpenAI å…¼å®¹çš„ API
- ğŸ’¬ æµå¼å’Œéæµå¼å“åº”
- ğŸ”„ å®æ—¶å¯¹è¯ä½“éªŒ
- âš™ï¸ ç¯å¢ƒå˜é‡é…ç½®

## å®‰è£…ä¾èµ–

```bash
cd agent
pip install -r requirements.txt
```

## é…ç½®

1. å¤åˆ¶ç¯å¢ƒå˜é‡ç¤ºä¾‹æ–‡ä»¶ï¼š
```bash
cp .env.example .env
```

2. ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œå¡«å…¥æ‚¨çš„ API é…ç½®ï¼š
```env
LLM_MODEL_ID=your-model-id
LLM_API_KEY=your-api-key
LLM_BASE_URL=https://api.openai.com/v1
LLM_TIMEOUT=60
AGENT_PORT=5000
```

## å¯åŠ¨æœåŠ¡

```bash
python app.py
```

æœåŠ¡å°†åœ¨ `http://localhost:5000` å¯åŠ¨ã€‚

## API æ¥å£

### å¥åº·æ£€æŸ¥
```
GET /health
```

### èŠå¤©ï¼ˆéæµå¼ï¼‰
```
POST /api/chat
Content-Type: application/json

{
  "messages": [
    {"role": "user", "content": "ä½ å¥½"}
  ],
  "temperature": 0.7
}
```

### èŠå¤©ï¼ˆæµå¼ï¼‰
```
POST /api/chat/stream
Content-Type: application/json

{
  "messages": [
    {"role": "user", "content": "ä½ å¥½"}
  ],
  "temperature": 0.7
}
```

å“åº”æ ¼å¼ä¸º Server-Sent Events (SSE)ã€‚

## ä½¿ç”¨ç¤ºä¾‹

```python
from llm_client import HelloAgentsLLM

# åˆå§‹åŒ–å®¢æˆ·ç«¯
llm = HelloAgentsLLM()

# å‘é€æ¶ˆæ¯
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•"}
]

response = llm.think(messages)
print(response)
```

