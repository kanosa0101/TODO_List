from flask import Flask, request, jsonify, Response, stream_with_context
from flask_cors import CORS
from dotenv import load_dotenv
import json
import os

# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆagentç›®å½•ï¼‰
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ENV_FILE = os.path.join(BASE_DIR, '.env')

# å…ˆåŠ è½½ .env æ–‡ä»¶ï¼ˆæŒ‡å®šç»å¯¹è·¯å¾„ï¼‰
load_dotenv(ENV_FILE)

from llm_client import HelloAgentsLLM

app = Flask(__name__)
# é…ç½® CORSï¼Œå…è®¸å‰ç«¯è·¨åŸŸè¯·æ±‚
CORS(app, resources={
    r"/api/*": {
        "origins": ["http://localhost:3000", "http://127.0.0.1:3000"],
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type", "Authorization"]
    }
})

# åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
llm_client = None
try:
    print("=" * 50)
    print("æ­£åœ¨åˆå§‹åŒ– LLM å®¢æˆ·ç«¯...")
    # æ˜¾ç¤ºå½“å‰ç¯å¢ƒå˜é‡ï¼ˆä¸æ˜¾ç¤ºæ•æ„Ÿä¿¡æ¯ï¼‰
    model_id = os.getenv("LLM_MODEL_ID", "").strip().strip('"').strip("'")
    base_url = os.getenv("LLM_BASE_URL", "").strip().strip('"').strip("'")
    api_key = os.getenv("LLM_API_KEY", "")
    if api_key:
        api_key_display = api_key[:10] + "..." if len(api_key) > 10 else "***"
    else:
        api_key_display = "æœªè®¾ç½®"
    
    print(f"   è¯»å–é…ç½®:")
    print(f"   - LLM_MODEL_ID: {model_id if model_id else '(æœªè®¾ç½®)'}")
    print(f"   - LLM_BASE_URL: {base_url if base_url else '(æœªè®¾ç½®)'}")
    print(f"   - LLM_API_KEY: {api_key_display}")
    print()
    
    llm_client = HelloAgentsLLM()
    print("âœ… LLM å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    print(f"   æ¨¡å‹: {llm_client.model}")
    print("=" * 50)
except Exception as e:
    print("=" * 50)
    print(f"âŒ LLM å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
    print()
    print("è¯·æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„é…ç½®:")
    print("  - LLM_MODEL_ID (æ¨¡å‹ID)")
    print("  - LLM_API_KEY (APIå¯†é’¥)")
    print("  - LLM_BASE_URL (æœåŠ¡åœ°å€)")
    print()
    print("æç¤º: .env æ–‡ä»¶ä¸­çš„å€¼ä¸éœ€è¦åŠ å¼•å·ï¼Œä¾‹å¦‚:")
    print("  LLM_MODEL_ID=your-model-id")
    print("  LLM_API_KEY=your-api-key")
    print("  LLM_BASE_URL=https://api.example.com/v1")
    print("=" * 50)
    llm_client = None

@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({
        'status': 'ok',
        'llm_ready': llm_client is not None
    })

@app.route('/api/chat', methods=['POST'])
def chat():
    """èŠå¤©æ¥å£ - éæµå¼å“åº”"""
    if not llm_client:
        return jsonify({'error': 'LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–'}), 500
    
    try:
        data = request.get_json()
        messages = data.get('messages', [])
        temperature = data.get('temperature', 0)
        
        if not messages:
            return jsonify({'error': 'æ¶ˆæ¯ä¸èƒ½ä¸ºç©º'}), 400
        
        response_text = llm_client.think(messages, temperature)
        
        if response_text is None:
            return jsonify({'error': 'LLMè°ƒç”¨å¤±è´¥'}), 500
        
        return jsonify({
            'response': response_text,
            'model': llm_client.model
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/chat/stream', methods=['POST'])
def chat_stream():
    """èŠå¤©æ¥å£ - æµå¼å“åº”"""
    if not llm_client:
        return jsonify({'error': 'LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–'}), 500
    
    try:
        data = request.get_json()
        messages = data.get('messages', [])
        temperature = data.get('temperature', 0)
        
        if not messages:
            return jsonify({'error': 'æ¶ˆæ¯ä¸èƒ½ä¸ºç©º'}), 400
        
        def generate():
            try:
                for chunk in llm_client.think_stream(messages, temperature):
                    if chunk is None:
                        yield f"data: {json.dumps({'error': 'LLMè°ƒç”¨å¤±è´¥'})}\n\n"
                        break
                    yield f"data: {json.dumps({'content': chunk})}\n\n"
                yield f"data: {json.dumps({'done': True})}\n\n"
            except Exception as e:
                yield f"data: {json.dumps({'error': str(e)})}\n\n"
        
        return Response(
            stream_with_context(generate()),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'X-Accel-Buffering': 'no'
            }
        )
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# å¦‚æœç›´æ¥è¿è¡Œ app.pyï¼Œä½¿ç”¨ç®€å•çš„å¯åŠ¨æ–¹å¼
if __name__ == '__main__':
    # .env æ–‡ä»¶å·²ç»åœ¨æ–‡ä»¶é¡¶éƒ¨åŠ è½½è¿‡äº†
    port = int(os.getenv('AGENT_PORT', 5000))
    print("=" * 60)
    print("ğŸš€ å¯åŠ¨ Agent æœåŠ¡...")
    print(f"   åœ°å€: http://0.0.0.0:{port}")
    print(f"   æœ¬åœ°: http://localhost:{port}")
    print(f"   LLM å°±ç»ª: {'æ˜¯' if llm_client else 'å¦'}")
    if not llm_client:
        print("   âš ï¸  è­¦å‘Š: LLM å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼ŒæœåŠ¡å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
    print("=" * 60)
    print()
    try:
        app.run(host='0.0.0.0', port=port, debug=True)
    except OSError as e:
        if "Address already in use" in str(e) or "address already in use" in str(e).lower():
            print(f"âŒ ç«¯å£ {port} å·²è¢«å ç”¨")
            print("   è¯·æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–ç¨‹åºåœ¨ä½¿ç”¨è¯¥ç«¯å£")
        else:
            print(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        input("\næŒ‰ Enter é”®é€€å‡º...")
    except Exception as e:
        print(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        input("\næŒ‰ Enter é”®é€€å‡º...")

