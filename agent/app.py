from flask import Flask, request, jsonify, Response, stream_with_context
from flask_cors import CORS
from dotenv import load_dotenv
import json
import os
import logging
from datetime import datetime

# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆagentç›®å½•ï¼‰
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ENV_FILE = os.path.join(BASE_DIR, '.env')

# å…ˆåŠ è½½ .env æ–‡ä»¶ï¼ˆæŒ‡å®šç»å¯¹è·¯å¾„ï¼‰
load_dotenv(ENV_FILE)

from llm_client import HelloAgentsLLM
from mcp_tools import get_mcp_tools, execute_tool

app = Flask(__name__)
# é…ç½® CORSï¼Œå…è®¸å‰ç«¯è·¨åŸŸè¯·æ±‚
CORS(app, resources={
    r"/api/*": {
        "origins": ["http://localhost:3000", "http://127.0.0.1:3000"],
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type", "Authorization"]
    }
})

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# è®¾ç½®è¯·æ±‚/å“åº”æ—¥å¿—ä¸­é—´ä»¶
try:
    from middleware import setup_request_logging
    setup_request_logging(app)
    logger.info("âœ“ è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶å·²å¯ç”¨")
except Exception as e:
    logger.warning(f"âš  è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶å¯ç”¨å¤±è´¥: {e}")

# åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
llm_client = None
try:
    print("=" * 50)
    print("æ­£åœ¨åˆå§‹åŒ– LLM å®¢æˆ·ç«¯...")
    # æ˜¾ç¤ºå½“å‰ç¯å¢ƒå˜é‡ï¼ˆä¸æ˜¾ç¤ºæ•æ„Ÿä¿¡æ¯ï¼‰
    model_id = os.getenv("LLM_MODEL_ID", "").strip().strip('"').strip("'")
    base_url = os.getenv("LLM_BASE_URL", "").strip().strip('"').strip("'")
    api_key = os.getenv("LLM_API_KEY", "")
    if api_key:
        api_key_display = api_key[:10] + "..." if len(api_key) > 10 else "***"
    else:
        api_key_display = "æœªè®¾ç½®"
    
    print(f"   è¯»å–é…ç½®:")
    print(f"   - LLM_MODEL_ID: {model_id if model_id else '(æœªè®¾ç½®)'}")
    print(f"   - LLM_BASE_URL: {base_url if base_url else '(æœªè®¾ç½®)'}")
    print(f"   - LLM_API_KEY: {api_key_display}")
    print()
    
    llm_client = HelloAgentsLLM()
    print("âœ… LLM å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    print(f"   æ¨¡å‹: {llm_client.model}")
    print("=" * 50)
except Exception as e:
    print("=" * 50)
    print(f"âŒ LLM å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
    print()
    print("è¯·æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„é…ç½®:")
    print("  - LLM_MODEL_ID (æ¨¡å‹ID)")
    print("  - LLM_API_KEY (APIå¯†é’¥)")
    print("  - LLM_BASE_URL (æœåŠ¡åœ°å€)")
    print()
    print("æç¤º: .env æ–‡ä»¶ä¸­çš„å€¼ä¸éœ€è¦åŠ å¼•å·ï¼Œä¾‹å¦‚:")
    print("  LLM_MODEL_ID=your-model-id")
    print("  LLM_API_KEY=your-api-key")
    print("  LLM_BASE_URL=https://api.example.com/v1")
    print("=" * 50)
    llm_client = None

@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({
        'status': 'ok',
        'llm_ready': llm_client is not None
    })

@app.route('/api/chat', methods=['POST'])
def chat():
    """èŠå¤©æ¥å£ - éæµå¼å“åº”"""
    request_id = datetime.now().strftime('%Y%m%d%H%M%S%f')[:-3]
    logger.info(f"[{request_id}] ========== æ”¶åˆ°éæµå¼èŠå¤©è¯·æ±‚ ==========")
    logger.info(f"[{request_id}] è¯·æ±‚æ¥æº: {request.remote_addr}")
    
    if not llm_client:
        logger.error(f"[{request_id}] LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        return jsonify({'error': 'LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–'}), 500
    
    try:
        data = request.get_json()
        messages = data.get('messages', [])
        temperature = data.get('temperature', 0)
        
        logger.info(f"[{request_id}] è¯·æ±‚å‚æ•°:")
        logger.info(f"[{request_id}]   - æ¶ˆæ¯æ•°é‡: {len(messages)}")
        logger.info(f"[{request_id}]   - æ¸©åº¦: {temperature}")
        if messages:
            logger.info(f"[{request_id}]   - æ¶ˆæ¯å†…å®¹:")
            for i, msg in enumerate(messages):
                role = msg.get('role', 'unknown')
                content = msg.get('content', '')
                logger.info(f"[{request_id}]     [{i+1}] {role}: {content[:100]}{'...' if len(content) > 100 else ''}")
        
        if not messages:
            logger.warning(f"[{request_id}] æ¶ˆæ¯ä¸ºç©º")
            return jsonify({'error': 'æ¶ˆæ¯ä¸èƒ½ä¸ºç©º'}), 400
        
        logger.info(f"[{request_id}] æ­£åœ¨è°ƒç”¨ LLM (æ¨¡å‹: {llm_client.model})...")
        start_time = datetime.now()
        
        response_text = llm_client.think(messages, temperature)
        
        elapsed = (datetime.now() - start_time).total_seconds()
        
        if response_text is None:
            logger.error(f"[{request_id}] LLMè°ƒç”¨å¤±è´¥ï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
            return jsonify({'error': 'LLMè°ƒç”¨å¤±è´¥'}), 500
        
        logger.info(f"[{request_id}] LLMè°ƒç”¨æˆåŠŸï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
        logger.info(f"[{request_id}] å“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")
        logger.info(f"[{request_id}] å“åº”é¢„è§ˆ: {response_text[:200]}{'...' if len(response_text) > 200 else ''}")
        logger.info(f"[{request_id}] ========== è¯·æ±‚å®Œæˆ ==========")
        
        return jsonify({
            'response': response_text,
            'model': llm_client.model
        })
    except Exception as e:
        logger.error(f"[{request_id}] å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        import traceback
        logger.error(f"[{request_id}] å¼‚å¸¸å †æ ˆ:\n{traceback.format_exc()}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/chat/stream', methods=['POST'])
def chat_stream():
    """èŠå¤©æ¥å£ - æµå¼å“åº”ï¼Œæ”¯æŒ MCP å·¥å…·è°ƒç”¨"""
    request_id = datetime.now().strftime('%Y%m%d%H%M%S%f')[:-3]
    logger.info(f"[{request_id}] ========== æ”¶åˆ°æ–°çš„èŠå¤©è¯·æ±‚ ==========")
    logger.info(f"[{request_id}] è¯·æ±‚æ¥æº: {request.remote_addr}")
    
    if not llm_client:
        logger.error(f"[{request_id}] LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        return jsonify({'error': 'LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–'}), 500
    
    try:
        data = request.get_json()
        messages = data.get('messages', [])
        temperature = data.get('temperature', 0)
        user_token = request.headers.get('Authorization', '').replace('Bearer ', '')
        
        logger.info(f"[{request_id}] è¯·æ±‚å‚æ•°:")
        logger.info(f"[{request_id}]   - æ¶ˆæ¯æ•°é‡: {len(messages)}")
        logger.info(f"[{request_id}]   - æ¸©åº¦: {temperature}")
        logger.info(f"[{request_id}]   - ç”¨æˆ·Token: {'å·²æä¾›' if user_token else 'æœªæä¾›'}")
        
        if messages:
            logger.info(f"[{request_id}]   - å®Œæ•´æ¶ˆæ¯å†å²:")
            for i, msg in enumerate(messages):
                role = msg.get('role', 'unknown')
                content = msg.get('content', '')
                logger.info(f"[{request_id}]     [{i+1}] {role}: {content[:150]}{'...' if len(content) > 150 else ''}")
        
        if not messages:
            logger.warning(f"[{request_id}] æ¶ˆæ¯ä¸ºç©ºï¼Œè¿”å›é”™è¯¯")
            return jsonify({'error': 'æ¶ˆæ¯ä¸èƒ½ä¸ºç©º'}), 400
        
        # è·å– MCP å·¥å…·å®šä¹‰
        tools = get_mcp_tools()
        logger.info(f"[{request_id}] å·²åŠ è½½ {len(tools)} ä¸ª MCP å·¥å…·")
        
        def generate():
            try:
                current_messages = messages.copy()
                
                # å¦‚æœæœ‰ tokenï¼Œæ·»åŠ ç³»ç»Ÿæç¤ºï¼Œå‘ŠçŸ¥ LLM å¯ä»¥ä½¿ç”¨å·¥å…·
                if user_token:
                    system_message = {
                        "role": "system",
                        "content": """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·ç®¡ç†å¾…åŠäº‹é¡¹å’Œç¬”è®°ã€‚
ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹åŠŸèƒ½ï¼š
1. æŸ¥çœ‹ã€åˆ›å»ºã€æ›´æ–°ã€åˆ é™¤å¾…åŠäº‹é¡¹
2. æŸ¥çœ‹ã€åˆ›å»ºã€æ›´æ–°ã€åˆ é™¤ç¬”è®°

å½“ç”¨æˆ·è¯·æ±‚æŸ¥çœ‹æˆ–æ“ä½œå¾…åŠäº‹é¡¹å’Œç¬”è®°æ—¶ï¼Œä½ åº”è¯¥ä¸»åŠ¨ä½¿ç”¨ç›¸åº”çš„å·¥å…·ã€‚
æ“ä½œå®Œæˆåï¼Œç”¨è‡ªç„¶è¯­è¨€å‘ç”¨æˆ·è¯´æ˜æ“ä½œç»“æœã€‚"""
                    }
                    # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç³»ç»Ÿæ¶ˆæ¯
                    has_system = any(msg.get("role") == "system" for msg in current_messages)
                    if not has_system:
                        current_messages.insert(0, system_message)
                
                max_iterations = 10  # é˜²æ­¢æ— é™å¾ªç¯
                iteration = 0
                
                while iteration < max_iterations:
                    iteration += 1
                    logger.info(f"[{request_id}] ---------- è¿­ä»£ {iteration}/{max_iterations} ----------")
                    logger.info(f"[{request_id}] å½“å‰æ¶ˆæ¯å†å²é•¿åº¦: {len(current_messages)}")
                    
                    # è°ƒç”¨ LLMï¼Œä¼ å…¥å·¥å…·å®šä¹‰
                    try:
                        logger.info(f"[{request_id}] æ­£åœ¨è°ƒç”¨ LLM (æ¨¡å‹: {llm_client.model})...")
                        start_time = datetime.now()
                        
                        # ä½¿ç”¨ stream=True è¿›è¡Œæµå¼è°ƒç”¨
                        response_stream = llm_client.client.chat.completions.create(
                            model=llm_client.model,
                            messages=current_messages,
                            temperature=temperature,
                            tools=tools if user_token else None,
                            tool_choice="auto" if user_token else None,
                            stream=True
                        )
                        
                        # ç”¨äºæ”¶é›†å®Œæ•´å“åº”
                        full_content = ""
                        tool_calls_data = {}  # index -> {id, type, function: {name, arguments}}
                        
                        # å¤„ç†æµå¼å“åº”
                        for chunk in response_stream:
                            delta = chunk.choices[0].delta
                            
                            # å¤„ç†å†…å®¹
                            if delta.content:
                                content_chunk = delta.content
                                full_content += content_chunk
                                # å®æ—¶æµå¼è¿”å›å†…å®¹ç»™å‰ç«¯
                                yield f"data: {json.dumps({'content': content_chunk})}\n\n"
                            
                            # å¤„ç†å·¥å…·è°ƒç”¨
                            if delta.tool_calls:
                                for tc in delta.tool_calls:
                                    idx = tc.index
                                    if idx not in tool_calls_data:
                                        tool_calls_data[idx] = {
                                            "id": "",
                                            "type": "function",
                                            "function": {"name": "", "arguments": ""}
                                        }
                                    
                                    if tc.id:
                                        tool_calls_data[idx]["id"] += tc.id
                                    if tc.function and tc.function.name:
                                        tool_calls_data[idx]["function"]["name"] += tc.function.name
                                    if tc.function and tc.function.arguments:
                                        tool_calls_data[idx]["function"]["arguments"] += tc.function.arguments
                        
                        elapsed = (datetime.now() - start_time).total_seconds()
                        logger.info(f"[{request_id}] LLM æµå¼è°ƒç”¨å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
                        
                        # æ„é€ å®Œæ•´çš„ tool_calls åˆ—è¡¨
                        tool_calls = []
                        if tool_calls_data:
                            for idx in sorted(tool_calls_data.keys()):
                                tc_data = tool_calls_data[idx]
                                tool_calls.append({
                                    "id": tc_data["id"],
                                    "type": tc_data["type"],
                                    "function": {
                                        "name": tc_data["function"]["name"],
                                        "arguments": tc_data["function"]["arguments"]
                                    }
                                })
                        
                        # æ„é€ å®Œæ•´çš„ message å¯¹è±¡ (æ¨¡æ‹Ÿ OpenAI Message å¯¹è±¡ç»“æ„)
                        class MockMessage:
                            def __init__(self, content, tool_calls):
                                self.content = content
                                self.tool_calls = tool_calls
                        
                        message = MockMessage(full_content, tool_calls if tool_calls else None)
                        
                        logger.info(f"[{request_id}] LLM å®Œæ•´å“åº”:")
                        logger.info(f"[{request_id}]   - æœ‰å·¥å…·è°ƒç”¨: {bool(message.tool_calls)}")
                        logger.info(f"[{request_id}]   - æœ‰å†…å®¹: {bool(message.content)}")
                        if message.content:
                            logger.info(f"[{request_id}]   - å†…å®¹é¢„è§ˆ: {message.content[:200]}")

                    except Exception as e:
                        logger.error(f"[{request_id}] LLMè°ƒç”¨å¤±è´¥: {str(e)}")
                        yield f"data: {json.dumps({'error': f'LLMè°ƒç”¨å¤±è´¥: {str(e)}'})}\n\n"
                        break
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                    if message.tool_calls and user_token:
                        logger.info(f"[{request_id}] æ£€æµ‹åˆ° {len(message.tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
                        # æ·»åŠ  assistant çš„å“åº”åˆ°æ¶ˆæ¯å†å²ï¼ˆåŒ…å«å·¥å…·è°ƒç”¨ï¼‰
                        assistant_message = {
                            "role": "assistant",
                            "content": message.content or None,
                            "tool_calls": message.tool_calls
                        }
                        current_messages.append(assistant_message)
                        
                        # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
                        for idx, tool_call in enumerate(message.tool_calls, 1):
                            # æ³¨æ„ï¼šè¿™é‡Œ tool_call æ˜¯å­—å…¸ï¼Œä¸æ˜¯å¯¹è±¡ï¼Œå› ä¸ºæˆ‘ä»¬æ‰‹åŠ¨æ„é€ çš„
                            tool_name = tool_call['function']['name']
                            try:
                                arguments = json.loads(tool_call['function']['arguments'])
                                logger.info(f"[{request_id}] å·¥å…·è°ƒç”¨ {idx}/{len(message.tool_calls)}: {tool_name}")
                                logger.info(f"[{request_id}]   å‚æ•°: {json.dumps(arguments, ensure_ascii=False, indent=2)}")
                            except json.JSONDecodeError as e:
                                arguments = {}
                                logger.error(f"[{request_id}] å·¥å…·è°ƒç”¨å‚æ•°è§£æå¤±è´¥ {idx}/{len(message.tool_calls)}: {tool_name}")
                                logger.error(f"[{request_id}]   é”™è¯¯: {str(e)}")
                                logger.error(f"[{request_id}]   åŸå§‹å‚æ•°: {tool_call['function']['arguments']}")
                            
                            # æ‰§è¡Œå·¥å…·
                            tool_start_time = datetime.now()
                            tool_result = execute_tool(user_token, tool_name, arguments)
                            tool_elapsed = (datetime.now() - tool_start_time).total_seconds()
                            
                            logger.info(f"[{request_id}] å·¥å…·æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {tool_elapsed:.2f}ç§’")
                            logger.info(f"[{request_id}]   æˆåŠŸ: {tool_result.get('success', False)}")
                            if tool_result.get('success', False):
                                # è®°å½•æˆåŠŸçš„å·¥å…·ç»“æœï¼ˆæˆªæ–­é•¿å†…å®¹ï¼‰
                                result_str = json.dumps(tool_result, ensure_ascii=False)
                                logger.info(f"[{request_id}]   ç»“æœ: {result_str[:300]}{'...' if len(result_str) > 300 else ''}")
                            else:
                                logger.error(f"[{request_id}]   å¤±è´¥åŸå› : {tool_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                                logger.error(f"[{request_id}]   å®Œæ•´ç»“æœ: {json.dumps(tool_result, ensure_ascii=False)}")
                            
                            # æ·»åŠ å·¥å…·è°ƒç”¨ç»“æœåˆ°æ¶ˆæ¯å†å²
                            current_messages.append({
                                "role": "tool",
                                "tool_call_id": tool_call['id'],
                                "name": tool_name,
                                "content": json.dumps(tool_result, ensure_ascii=False)
                            })
                        
                        # ç»§ç»­å¾ªç¯ï¼Œè®© LLM åŸºäºå·¥å…·ç»“æœç”Ÿæˆå›å¤
                        continue
                    
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œä¸”å·²ç»æµå¼è¿”å›äº†å†…å®¹
                    if message.content:
                        logger.info(f"[{request_id}] æœ€ç»ˆå“åº”å·²æµå¼å‘é€å®Œæ¯•")
                        current_messages.append({
                            "role": "assistant",
                            "content": message.content
                        })
                        yield f"data: {json.dumps({'done': True})}\n\n"
                        logger.info(f"[{request_id}] ========== è¯·æ±‚å®Œæˆ ==========")
                        break
                    else:
                        # å¦‚æœæ²¡æœ‰å†…å®¹ä¸”æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼ˆå¼‚å¸¸æƒ…å†µï¼‰ï¼Œæˆ–è€…éœ€è¦ç”Ÿæˆæœ€ç»ˆå›å¤ï¼ˆç†è®ºä¸Š stream=True åº”è¯¥å·²ç»å¤„ç†äº†å†…å®¹ï¼‰
                        # ä½†å¦‚æœ stream=True è¿”å›äº†ç©ºå†…å®¹ä¸”æ— å·¥å…·è°ƒç”¨ï¼Œå¯èƒ½æ˜¯å‡ºé”™äº†
                        logger.warning(f"[{request_id}] LLMæœªè¿”å›ä»»ä½•å†…å®¹ä¸”æ— å·¥å…·è°ƒç”¨")
                        yield f"data: {json.dumps({'error': 'LLMæœªè¿”å›æœ‰æ•ˆå†…å®¹'})}\n\n"
                        break
                
            except Exception as e:
                logger.error(f"[{request_id}] ç”Ÿæˆå“åº”æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
                import traceback
                logger.error(f"[{request_id}] å¼‚å¸¸å †æ ˆ:\n{traceback.format_exc()}")
                yield f"data: {json.dumps({'error': str(e)})}\n\n"
        
        return Response(
            stream_with_context(generate()),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'X-Accel-Buffering': 'no'
            }
        )
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# å¦‚æœç›´æ¥è¿è¡Œ app.pyï¼Œä½¿ç”¨ç®€å•çš„å¯åŠ¨æ–¹å¼
if __name__ == '__main__':
    # .env æ–‡ä»¶å·²ç»åœ¨æ–‡ä»¶é¡¶éƒ¨åŠ è½½è¿‡äº†
    port = int(os.getenv('AGENT_PORT', 5000))
    print("=" * 60)
    print("ğŸš€ å¯åŠ¨ Agent æœåŠ¡...")
    print(f"   åœ°å€: http://0.0.0.0:{port}")
    print(f"   æœ¬åœ°: http://localhost:{port}")
    print(f"   LLM å°±ç»ª: {'æ˜¯' if llm_client else 'å¦'}")
    if not llm_client:
        print("   âš ï¸  è­¦å‘Š: LLM å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼ŒæœåŠ¡å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
    print("=" * 60)
    print()
    try:
        app.run(host='0.0.0.0', port=port, debug=True)
    except OSError as e:
        if "Address already in use" in str(e) or "address already in use" in str(e).lower():
            print(f"âŒ ç«¯å£ {port} å·²è¢«å ç”¨")
            print("   è¯·æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–ç¨‹åºåœ¨ä½¿ç”¨è¯¥ç«¯å£")
        else:
            print(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        input("\næŒ‰ Enter é”®é€€å‡º...")
    except Exception as e:
        print(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        input("\næŒ‰ Enter é”®é€€å‡º...")

